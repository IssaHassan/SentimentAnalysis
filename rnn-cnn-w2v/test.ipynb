{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Dhrubo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "appos = {\n",
    "  \"aren't\" : \"are not\", \"can't\" : \"cannot\", \"couldn't\" : \"could not\", \"didn't\" : \"did not\",\n",
    "  \"doesn't\" : \"does not\", \"don't\" : \"do not\", \"hadn't\" : \"had not\", \"hasn't\" : \"has not\",\n",
    "  \"haven't\" : \"have not\", \"he'd\" : \"he would\", \"he'll\" : \"he will\", \"he's\" : \"he is\", \"i'd\" : \"i would\",\n",
    "  \"i'd\" : \"i had\", \"i'll\" : \"i will\", \"i'm\" : \"i am\", \"isn't\" : \"is not\", \"it's\" : \"it is\", \"it'll\":\"it will\",\n",
    "  \"i've\" : \"I have\", \"let's\" : \"let us\", \"mightn't\" : \"might not\", \"mustn't\" : \"must not\", \"shan't\" : \"shall not\",\n",
    "  \"she'd\" : \"she would\", \"she'll\" : \"she will\", \"she's\" : \"she is\", \"shouldn't\" : \"should not\", \"that's\" : \"that is\",\n",
    "  \"there's\" : \"there is\", \"they'd\" : \"they would\", \"they'll\" : \"they will\", \"they're\" : \"they are\", \"they've\" : \"they have\",\n",
    "  \"we'd\" : \"we would\", \"we're\" : \"we are\", \"weren't\" : \"were not\", \"we've\" : \"we have\", \"what'll\" : \"what will\",\n",
    "  \"what're\" : \"what are\", \"what's\" : \"what is\", \"what've\" : \"what have\", \"where's\" : \"where is\", \"who'd\" : \"who would\",\n",
    "  \"who'll\" : \"who will\", \"who're\" : \"who are\", \"who's\" : \"who is\", \"who've\" : \"who have\", \"won't\" : \"will not\",\n",
    "  \"wouldn't\" : \"would not\", \"you'd\" : \"you would\", \"you'll\" : \"you will\", \"you're\" : \"you are\", \"you've\" : \"you have\",\n",
    "  \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\":\" will\", \"didn't\": \"did not\"\n",
    "}\n",
    "\n",
    "def clean_text(text):\n",
    "  # Remove whitespaces and make strings lowercase\n",
    "  text = text.strip().lower()\n",
    "  words = text.split()\n",
    "  # Nagation handling\n",
    "  reformed = [appos[word] if word in appos else word for word in words]\n",
    "  text = \" \".join(reformed)\n",
    "  pattern = '(@(\\w+))'                # usermention (@username)\n",
    "  pattern += '|(#(\\w+))'              # hashtags (#somehashtag)\n",
    "  pattern += '|([^\\w\\s])'             # emojis ðŸ˜€\n",
    "  pattern += '|(\\\\w+:\\\\/\\\\/\\\\S+)'     # urls (https://google.com)\n",
    "  pattern += '|(\\d+)'                 # numbers\n",
    "  text = ' '.join(re.sub(pattern, ' ', text).split())\n",
    "  return text\n",
    "\n",
    "\n",
    "def get_accuracy(data_path, tokenizer_path, model_path):\n",
    "  data = pd.read_csv(data_path)\n",
    "  ho_x_test = data['Tweet'].map(lambda t: clean_text(t))\n",
    "  ho_y_test = data['Sentiment']\n",
    "  # load tokenizer: \n",
    "  # That's the one we will use to vectorize our data where we want to get the prediction\n",
    "  with open(tokenizer_path, 'rb') as handle:\n",
    "      tokenizer = pickle.load(handle)\n",
    "  # load rnn model\n",
    "  rnn_model = load_model(model_path)\n",
    "  ho_test_sequences = tokenizer.texts_to_sequences(ho_x_test)\n",
    "  padded_ho_test_sequences = pad_sequences(ho_test_sequences, maxlen=35)\n",
    "  ho_y_pred = rnn_model.predict(padded_ho_test_sequences, verbose=1, batch_size=2048)\n",
    "  ho_y_pred = pd.DataFrame(ho_y_pred, columns=['prediction'])\n",
    "  ho_y_pred['prediction'] = ho_y_pred['prediction'].map(lambda p: 1 if p >= 0.5 else 0)\n",
    "  return accuracy_score(ho_y_test, ho_y_pred)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 1s 5ms/step\n",
      "Hydro Ottawa dataset accuracy:  66.80672268907563\n",
      "443/443 [==============================] - 1s 3ms/step\n",
      "Manually created dataset accuracy:  88.71331828442437\n"
     ]
    }
   ],
   "source": [
    "# RNN-CNN epoch-1\n",
    "print('Hydro Ottawa dataset accuracy: ', \n",
    "      get_accuracy('../data/HydroOttawaAnnotatedData.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-01-0.8362.hdf5'))\n",
    "\n",
    "print('Manually created dataset accuracy: ',\n",
    "      get_accuracy('../data/CompiledTweets.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-01-0.8362.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 1s 6ms/step\n",
      "Hydro Ottawa dataset accuracy:  71.42857142857143\n",
      "443/443 [==============================] - 2s 4ms/step\n",
      "Manually created dataset accuracy:  90.51918735891647\n"
     ]
    }
   ],
   "source": [
    "# RNN-CNN epoch-2\n",
    "print('Hydro Ottawa dataset accuracy: ', \n",
    "      get_accuracy('../data/HydroOttawaAnnotatedData.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-02-0.8399.hdf5'))\n",
    "\n",
    "print('Manually created dataset accuracy: ',\n",
    "      get_accuracy('../data/CompiledTweets.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-02-0.8399.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 1s 6ms/step\n",
      "Hydro Ottawa dataset accuracy:  66.80672268907563\n",
      "443/443 [==============================] - 2s 4ms/step\n",
      "Manually created dataset accuracy:  91.87358916478556\n"
     ]
    }
   ],
   "source": [
    "# RNN-CNN epoch-3\n",
    "print('Hydro Ottawa dataset accuracy: ', \n",
    "      get_accuracy('../data/HydroOttawaAnnotatedData.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-03-0.8419.hdf5'))\n",
    "\n",
    "print('Manually created dataset accuracy: ',\n",
    "      get_accuracy('../data/CompiledTweets.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-03-0.8419.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 1s 4ms/step\n",
      "Hydro Ottawa dataset accuracy:  71.00840336134453\n",
      "443/443 [==============================] - 1s 3ms/step\n",
      "Manually created dataset accuracy:  88.48758465011286\n"
     ]
    }
   ],
   "source": [
    "# RNN-CNN epoch-4\n",
    "print('Hydro Ottawa dataset accuracy: ', \n",
    "      get_accuracy('../data/HydroOttawaAnnotatedData.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-04-0.8421.hdf5'))\n",
    "\n",
    "print('Manually created dataset accuracy: ',\n",
    "      get_accuracy('../data/CompiledTweets.csv',\n",
    "                   'tokenizer-rnn-cnn-w2v.pickle',\n",
    "                   './models/rnn-cnn-w2v-model-04-0.8421.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
