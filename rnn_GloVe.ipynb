{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn-GloVe.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fV3y6qryQrQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c34e2f6f-ba1c-4620-8bba-3c92cd8f9d79"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UgJAstSNegB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7e9cc92e-ce9e-48cc-a825-343eb1bcb7e0"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/SentimentAnalysis/rnn/data/clean_data.csv', error_bad_lines=False)\n",
        "data.CleanText = data.CleanText.astype(str)\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentSource</th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>CleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "      <td>is so sad for my apl friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "      <td>i missed the new moon trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "      <td>omg its already 7 30 o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "      <td>omgaga im sooo im gunna cry i ve been at this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "      <td>i think mi bf is cheating on me t t</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ItemID  Sentiment SentimentSource  \\\n",
              "0       1          0    Sentiment140   \n",
              "1       2          0    Sentiment140   \n",
              "2       3          1    Sentiment140   \n",
              "3       4          0    Sentiment140   \n",
              "4       5          0    Sentiment140   \n",
              "\n",
              "                                       SentimentText  \\\n",
              "0                       is so sad for my APL frie...   \n",
              "1                     I missed the New Moon trail...   \n",
              "2                            omg its already 7:30 :O   \n",
              "3            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
              "4           i think mi bf is cheating on me!!!   ...   \n",
              "\n",
              "                                           CleanText  \n",
              "0                        is so sad for my apl friend  \n",
              "1                      i missed the new moon trailer  \n",
              "2                             omg its already 7 30 o  \n",
              "3  omgaga im sooo im gunna cry i ve been at this ...  \n",
              "4                i think mi bf is cheating on me t t  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "-yI3yOnAb2vn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# load tokenizer\n",
        "with open('/content/drive/My Drive/SentimentAnalysis/rnn/tokenizers/tokenizer.pickle', 'rb') as handle:\n",
        "  tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_aRv61sez1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f105839c-0646-4378-c40d-3ba827813d77"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['CleanText'], \n",
        "                                                    data['Sentiment'], \n",
        "                                                    test_size=0.1, \n",
        "                                                    random_state=42,\n",
        "                                                    stratify=data['Sentiment'])\n",
        "\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1420750,) (157862,) (1420750,) (157862,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yAd0sHSFfRs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67e67253-9904-4e88-8c58-a35d607425a9"
      },
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "MAX_LENGTH = 35\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen=MAX_LENGTH)\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen=MAX_LENGTH)\n",
        "\n",
        "padded_train_sequences.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1420750, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "lJRwhcP1Ggg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "d-5potRAlmTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "65d571a7-e6ad-495e-dd6b-c0a6d43184a1"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('/content/drive/My Drive/SentimentAnalysis/rnn/embeddings/glove.840B.300d.txt')\n",
        "f.tell()\n",
        "i = 0\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  try:\n",
        "    coefs = np.asarray(values[1:], dtype=np.float32)\n",
        "  except ValueError as e:\n",
        "    print(\"\\nValueError: \", e, \"\\n\")\n",
        "  embeddings_index[word] = coefs\n",
        "  i += 1\n",
        "  sys.stdout.write(\"\\r%d%%\" % i)\n",
        "  sys.stdout.flush()\n",
        "  \n",
        "f.close()\n",
        "print('*** Done! In Total, loaded %s word vectors ***' % len(embeddings_index))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128261%\n",
            "ValueError:  could not convert string to float: 'name@domain.com' \n",
            "\n",
            "151102%\n",
            "ValueError:  could not convert string to float: '.' \n",
            "\n",
            "209833%\n",
            "ValueError:  could not convert string to float: '.' \n",
            "\n",
            "220779%\n",
            "ValueError:  could not convert string to float: '.' \n",
            "\n",
            "253461%\n",
            "ValueError:  could not convert string to float: 'name@domain.com' \n",
            "\n",
            "365745%\n",
            "ValueError:  could not convert string to float: 'name@domain.com' \n",
            "\n",
            "532048%\n",
            "ValueError:  could not convert string to float: 'name@domain.com' \n",
            "\n",
            "717302%\n",
            "ValueError:  could not convert string to float: 'name@domain.com' \n",
            "\n",
            "994818%\n",
            "ValueError:  could not convert string to float: 'name@domain.com' \n",
            "\n",
            "1123331%\n",
            "ValueError:  could not convert string to float: 'Killerseats.com' \n",
            "\n",
            "1499727%\n",
            "ValueError:  could not convert string to float: 'name@domain.com' \n",
            "\n",
            "2196017%*** Done! In Total, loaded 2195884 word vectors ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yhiNeAszooFI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# load tokenizer, used in the simple rnn model previously \n",
        "with open('/content/drive/My Drive/SentimentAnalysis/rnn/tokenizers/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WhTXS0TAoqdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed_size = 300\n",
        "# maximum number of words kept after tokenization based on their word frequency\n",
        "MAX_NB_WORDS = 80000\n",
        "\n",
        "nb_words = MAX_NB_WORDS\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  if index > nb_words - 1:\n",
        "    break\n",
        "  else:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-yWLqygNdE0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7302dd24-4d00-4fff-d679-dc6e61967b76"
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "yJwUV7JfcTj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, GRU, Bidirectional\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
        "\n",
        "MAX_NB_WORDS = 80000\n",
        "\n",
        "def get_rnn_model_with_glove_embeddings():\n",
        "  embedding_dim = 300\n",
        "  inp = Input(shape=(MAX_LENGTH, ))\n",
        "  x = Embedding(MAX_NB_WORDS, embedding_dim, weights=[embedding_matrix], input_length=MAX_LENGTH, trainable=True)(inp)\n",
        "  x = SpatialDropout1D(0.3)(x)\n",
        "  x = Bidirectional(GRU(100, return_sequences=True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)\n",
        "\n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0ZTCaWbd-dE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "2c9a1b3d-f1b2-4748-92c7-78d39959eaaf"
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "rnn_model_with_embeddings = get_rnn_model_with_glove_embeddings()\n",
        "\n",
        "filepath=\"/content/drive/My Drive/SentimentAnalysis/rnn/models/rnn-glove-model-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 4\n",
        "\n",
        "history = rnn_model_with_embeddings.fit(x=padded_train_sequences, \n",
        "                    y=y_train, \n",
        "                    validation_data=(padded_test_sequences, y_test), \n",
        "                    batch_size=batch_size, \n",
        "                    callbacks=[checkpoint], \n",
        "                    epochs=epochs, \n",
        "                    verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1420750 samples, validate on 157862 samples\n",
            "Epoch 1/4\n",
            "1420750/1420750 [==============================] - 1358s 956us/step - loss: 0.3998 - acc: 0.8173 - val_loss: 0.3691 - val_acc: 0.8362\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.83617, saving model to /content/drive/My Drive/SentimentAnalysis/rnn/models/rnn-glove-model-01-0.8362.hdf5\n",
            "Epoch 2/4\n",
            "1420750/1420750 [==============================] - 1366s 962us/step - loss: 0.3533 - acc: 0.8435 - val_loss: 0.3608 - val_acc: 0.8406\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.83617 to 0.84063, saving model to /content/drive/My Drive/SentimentAnalysis/rnn/models/rnn-glove-model-02-0.8406.hdf5\n",
            "Epoch 3/4\n",
            "1420750/1420750 [==============================] - 1363s 959us/step - loss: 0.3277 - acc: 0.8570 - val_loss: 0.3655 - val_acc: 0.8396\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.84063\n",
            "Epoch 4/4\n",
            "1420750/1420750 [==============================] - 1288s 906us/step - loss: 0.3062 - acc: 0.8684 - val_loss: 0.3729 - val_acc: 0.8384\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.84063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R89US-klfykb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eedab6d0-cec3-4029-8c23-522be3020a21"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rnn_model_GloVe = load_model('/content/drive/My Drive/SentimentAnalysis/rnn/models/rnn-glove-model-01-0.8362.hdf5')\n",
        "\n",
        "y_pred = rnn_model_GloVe.predict(padded_test_sequences, verbose=1, batch_size=2048)\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred, columns=['prediction'])\n",
        "y_pred['prediction'] = y_pred['prediction'].map(lambda p: 1 if p >= 0.5 else 0)\n",
        "print('Accuracy of test set: ', accuracy_score(y_test, y_pred)*100, '%')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157862/157862 [==============================] - 8s 48us/step\n",
            "Accuracy of test set:  83.61733666113442 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8-FoPt1fXaOp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}