{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn-word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lkgp6rhb9Q6j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3fc3715c-415b-48a1-e4a5-2e18b8a63e56"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3R7OeLti-vqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8ed15fb8-e56c-44dc-ab7a-d1826cbaed8e"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/SentimentAnalysis/rnn/data/clean_data.csv', error_bad_lines=False)\n",
        "data.CleanText = data.CleanText.astype(str)\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentSource</th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>CleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "      <td>is so sad for my apl friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "      <td>i missed the new moon trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "      <td>omg its already 7 30 o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "      <td>omgaga im sooo im gunna cry i ve been at this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>Sentiment140</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "      <td>i think mi bf is cheating on me t t</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ItemID  Sentiment SentimentSource  \\\n",
              "0       1          0    Sentiment140   \n",
              "1       2          0    Sentiment140   \n",
              "2       3          1    Sentiment140   \n",
              "3       4          0    Sentiment140   \n",
              "4       5          0    Sentiment140   \n",
              "\n",
              "                                       SentimentText  \\\n",
              "0                       is so sad for my APL frie...   \n",
              "1                     I missed the New Moon trail...   \n",
              "2                            omg its already 7:30 :O   \n",
              "3            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
              "4           i think mi bf is cheating on me!!!   ...   \n",
              "\n",
              "                                           CleanText  \n",
              "0                        is so sad for my apl friend  \n",
              "1                      i missed the new moon trailer  \n",
              "2                             omg its already 7 30 o  \n",
              "3  omgaga im sooo im gunna cry i ve been at this ...  \n",
              "4                i think mi bf is cheating on me t t  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "EeaEY30SGt78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74ae38cf-71ba-4651-d6d3-5c847191069c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['CleanText'], \n",
        "                                                    data['Sentiment'], \n",
        "                                                    test_size=0.1, \n",
        "                                                    random_state=42,\n",
        "                                                    stratify=data['Sentiment'])\n",
        "\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1420750,) (157862,) (1420750,) (157862,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n9A4gR8rLGjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CoQvOzgzL-pA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def labelize_tweets_ug(tweets, label):\n",
        "  result = []\n",
        "  prefix = label\n",
        "  for i, t in zip(tweets.index, tweets):\n",
        "    result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
        "  return result\n",
        "\n",
        "all_x = pd.concat([x_train, x_test])\n",
        "all_x_w2v = labelize_tweets_ug(all_x, 'all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "71GV5PkXMFUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "77ce12db-549c-415c-c3f7-ad9e624e14d6"
      },
      "cell_type": "code",
      "source": [
        "all_x_w2v[1]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaggedDocument(words=['my', '6', 'yo', 'just', 'called', 'and', 'left', 'me', 'a', 'vm', 'he', 'said', 'i', 'love', 'you', 'mommy', 'and', 'it', 's', 'ok', 'to', 'come', 'pick', 'me', 'up', 'tomorrow', 'awww', 'now', 'mama', 'is', 'a', 'mess'], tags=['all_1009730'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "f0jCnT65MfuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d920f690-becf-4f6b-e5c5-cac41225934a"
      },
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "# Continuous Bag Of Words\n",
        "model_ug_cbow = Word2Vec(sg=0, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
        "model_ug_cbow.build_vocab([x.words for x in tqdm(all_x_w2v)])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2102111.62it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R8TjDALTN-w5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "387251db-dc94-4062-e661-722d58696707"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "  model_ug_cbow.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
        "  model_ug_cbow.alpha -= 0.002\n",
        "  model_ug_cbow.min_alpha = model_ug_cbow.alpha"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2237741.97it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2053260.73it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2125649.98it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2155943.56it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2147897.84it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2100907.01it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2110667.47it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2109827.44it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2121491.31it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2173850.35it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2143311.74it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2136760.82it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2095384.62it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2089547.57it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2108543.47it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2118970.41it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2121020.35it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2076591.45it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2118307.40it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2142379.67it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2101566.51it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2119198.29it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2116773.51it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2098953.63it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2100198.64it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2111154.04it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2113630.72it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2135626.40it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2170483.28it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2125127.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 31min 2s, sys: 10.7 s, total: 31min 13s\n",
            "Wall time: 16min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EQQW18vyOM13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6723b625-585f-46e9-f47c-1e2b0b8bdc9c"
      },
      "cell_type": "code",
      "source": [
        "# Skip Gram\n",
        "model_ug_sg = Word2Vec(sg=1, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
        "model_ug_sg.build_vocab([x.words for x in tqdm(all_x_w2v)])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2309020.50it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XovOngQWSOjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "5f94c052-9c4d-4131-ea23-f18d2ffcd5e8"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "  model_ug_sg.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
        "  model_ug_sg.alpha -= 0.002\n",
        "  model_ug_sg.min_alpha = model_ug_sg.alpha"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2201274.59it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2088717.01it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2054112.39it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2096763.49it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2087736.36it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2073157.74it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2078943.28it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2063905.03it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2070379.31it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2101359.08it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2104056.17it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2094639.54it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2093122.51it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2080756.90it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2093278.02it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2082987.11it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2018908.08it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2058663.53it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2098197.37it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2080247.65it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2097716.76it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2134443.64it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2101620.54it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2106618.77it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2142067.78it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2073515.47it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2078678.29it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2104468.79it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2108660.99it/s]\n",
            "100%|██████████| 1578612/1578612 [00:00<00:00, 2078750.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 54min 42s, sys: 11.3 s, total: 54min 53s\n",
            "Wall time: 28min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sMnViVuRSbJ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ug_cbow.save('w2v_model_ug_cbow.word2vec')\n",
        "model_ug_sg.save('w2v_model_ug_sg.word2vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IBcJq7VOavwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef51dfda-86cd-48b8-c255-73491bf8192f"
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_ug_cbow = KeyedVectors.load('/content/drive/My Drive/SentimentAnalysis/rnn/w2vmodels/w2v_model_ug_cbow.word2vec')\n",
        "model_ug_sg = KeyedVectors.load('/content/drive/My Drive/SentimentAnalysis/rnn/w2vmodels/w2v_model_ug_sg.word2vec')\n",
        "\n",
        "len(model_ug_cbow.wv.vocab.keys())"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "Iy87OaQBbhs4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e14d76e4-b2a5-43ed-d472-c779c4fa5114"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_index = {}\n",
        "for w in model_ug_cbow.wv.vocab.keys():\n",
        "    embeddings_index[w] = np.append(model_ug_cbow.wv[w],model_ug_sg.wv[w])\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 113945 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SLzGTGY8bkmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa1b5c94-f15c-46c2-8f41-e01f93065506"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "MAX_NB_WORDS = 80000\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(data['CleanText'])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gcq0pYEFcZna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
        "test_sequences = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iA0n3By6dCqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "154361c7-8444-45eb-fefa-76567cd95f66"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LENGTH = 35\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen=MAX_LENGTH)\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen=MAX_LENGTH)\n",
        "padded_train_sequences.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1420750, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "OlZ4seEWdOag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed_size = 200\n",
        "# maximum number of words kept after tokenization based on their word frequency\n",
        "MAX_NB_WORDS = 80000\n",
        "\n",
        "num_words = MAX_NB_WORDS\n",
        "embedding_matrix = np.zeros((num_words, embed_size))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i >= num_words:\n",
        "    continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2dDgB4AYeEub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7d1dd20-06a9-4fa9-b4f3-e377debdbbf5"
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "9aR9nfPQegC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, GRU, Bidirectional\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
        "\n",
        "MAX_NB_WORDS = 80000\n",
        "\n",
        "def get_rnn_model_with_word2vec():\n",
        "  embedding_dim = 200\n",
        "  inp = Input(shape=(MAX_LENGTH, ))\n",
        "  x = Embedding(MAX_NB_WORDS, embedding_dim, weights=[embedding_matrix], input_length=MAX_LENGTH, trainable=True)(inp)\n",
        "  x = SpatialDropout1D(0.3)(x)\n",
        "  x = Bidirectional(GRU(100, return_sequences=True))(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, max_pool])\n",
        "  outp = Dense(1, activation=\"sigmoid\")(conc)\n",
        "\n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQJz591JfDTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "765d4583-212a-45a0-addc-b02e6ee356ec"
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "rnn_model_with_word2vec = get_rnn_model_with_word2vec()\n",
        "\n",
        "filepath=\"/content/drive/My Drive/SentimentAnalysis/rnn/models/rnn-word2vec-model-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 4\n",
        "\n",
        "history = rnn_model_with_word2vec.fit(x=padded_train_sequences, \n",
        "                    y=y_train, \n",
        "                    validation_data=(padded_test_sequences, y_test), \n",
        "                    batch_size=batch_size, \n",
        "                    callbacks=[checkpoint], \n",
        "                    epochs=epochs, \n",
        "                    verbose=1)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-9b52dc358521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrnn_model_with_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rnn_model_with_word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/SentimentAnalysis/rnn/models/rnn-word2vec-model-{epoch:02d}-{val_acc:.4f}.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_rnn_model_with_word2vec' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2tKF_r1tfOYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12804bfa-a6a8-4565-fd69-e4470b178f2a"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rnn_model_word2vec = load_model('/content/drive/My Drive/SentimentAnalysis/rnn/models/rnn-word2vec-model-03-0.8425.hdf5')\n",
        "\n",
        "y_pred = rnn_model_word2vec.predict(padded_test_sequences, verbose=1, batch_size=2048)\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred, columns=['prediction'])\n",
        "y_pred['prediction'] = y_pred['prediction'].map(lambda p: 1 if p >= 0.5 else 0)\n",
        "print('Accuracy of test set: ', accuracy_score(y_test, y_pred)*100, '%')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157862/157862 [==============================] - 7s 43us/step\n",
            "Accuracy of test set:  84.25333519149638 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "85SJoUDPu71L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving tokenizer\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/SentimentAnalysis/rnn/tokenizers/tokenizer-rnn-word2vec.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfuuCU03v9fO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}